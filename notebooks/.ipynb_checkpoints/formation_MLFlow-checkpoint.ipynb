{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formation ML Flow\n",
    "\n",
    "L'objectif de cette formation est de vous apprendre à utiliser ML Flow, un dashboard pour expériences de Machine Learning. Cette formation vous montrera pas à pas comment lancer une expérience de Machine Learning et surveiller les paramètres, métriques et resultats de votre expérience grâce à ML Flow. \n",
    "\n",
    "Pour cela, la formation s'appuiera sur le célèbre jeu de donnée Iris, qui classifie 150 echantillons de fleur en 3 espèces d'iris : Iris setosa, Iris versicolor et Iris virginica. Le dataset comprend les caractéristiques de chaque échantillon (longueur et largeur des pétales et longueur et largeur des sépales) et nous allons donc essayer de créer plusieurs modèles qui essaieront de classifier les échantillons d'iris selon leurs caractéristiques. \n",
    "\n",
    "Commençons par importer les librairies qui vont nous servir :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Ouverture et visualisation du dataset Iris\n",
    "\n",
    "A présent ouvrons le fichier contenant le dataset et affichons les données concernant les 5 premiers échantillons :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('iris.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons maintenant quelques informations sur les caractéristiques des fleurs :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons le nombre d'échantillons pour chacune des espèces d'iris :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.groupby('class').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons maintenant le nuage de points de chaque paire de caractéristiques. Sur la diagonale, on retrouve un histogramme du nombre d'échantillons selon la valeur de la caractéristique. On peut remarquer certaines structures, par exemple des groupes, dans les relations entre certaines caractéristiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(dataset,figsize=(15,7))\n",
    "plt.suptitle('Scatter matrix of the Iris dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ML Flow : premiers pas avec un modèle aléatoire\n",
    "\n",
    "Nous allons maintenant réaliser un premier exemple de modèle de classification très simple : le modèle aléatoire. Ce modèle attribuera aléatoirement une classe à chaque échantillon du dataset. Nous visualiserons ensuite ses performances (pas très bonnes, on l'imagine) avec ML FLow.\n",
    "\n",
    "Commençons par séparer le dataset en 2 variables : les 4 caractéristiques d'une part (X), et l'espèce d'iris d'autre part (Y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = dataset.values\n",
    "X = array[:,0:4]\n",
    "Y = array[:,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construisons notre modèle aléatoire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy = DummyClassifier(strategy=\"uniform\")\n",
    "dummy.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons ses prédictions pour les premiers échantillons :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = dummy.predict(X)\n",
    "for i in range(5):\n",
    "    print(X[i], ', vraie classe : ', Y[i], ', prédiction : ', Y_pred[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant enregistrer les performances de ce magnifique modèle avec ML Flow. Pour l'instant executez les cellules suivantes \"bêtement\", nous expliquerons chaque ligne ensuite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name='Modele_Aleatoire'):\n",
    "    mlflow.log_param('MODEL_NAME', 'DummyClassifier')\n",
    "    mlflow.log_metric('Accuracy', accuracy_score(Y, Y_pred))\n",
    "    mlflow.log_artifact('iris.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant ouvrez un terminal et naviguez jusqu'au dossier ```formation-mlflow```. Affichez le contenu du dossier. Vous devriez y trouver un nouveau dossier nommé ```mlflow```. Ce dossier contient toutes les informations que nous avons enregistré précédemment.\n",
    "\n",
    "Toujours dans le dossier ```formation-mlflow```, entrez la commande ```mlflow ui```. Le message ```Serving on http://XXXXXXX:5000``` devrait s'afficher. Ouvrez maintenant un navigateur web et ouvrez une fenêtre vers l'url ```http://localhost:5000/```. Vous devriez voir apparaître le dashboard suivant :\n",
    "\n",
    "![dashboard](MLFlow.png)\n",
    "\n",
    "La ligne au milieu du tableau, comportant le nom ```Modele_Aleatoire``` correspond aux données que nous avons enregistré précédemment. Vous pouvez remarquer dans la colonne ```Parameters``` le paramètre  ```MODEL_NAME``` que nous avons enregistré, ainsi que la métrique ```Accuracy``` dans la colonne ```Metrics```. Maintenant cliquez sur cette ligne et vous trouverez le détail des informations concernant ce ```run```. Descendez jusqu'à la section ```Artifacts``` où vous pourrez voir une copie du fichier ```iris.csv```. En cliquant dessus vous pourrez le visualiser en entier.\n",
    "\n",
    "Revenons maintenant sur la façon dont nous avons enregistré ces informations avec ML FLow.\n",
    "\n",
    "ML Flow permet d'enregistrer puis visualiser 3 types de choses :\n",
    "* des **paramètres** : ce sont des valeurs (int, float, string, ...) qui ne varient pas au cours d'un 'run', ici ```MODEL_NAME``` est un paramètre.\n",
    "* des **métriques** : ce sont des valeurs numériques qui peuvent varier au cours du 'run', ici ```Accuracy``` est une métrique.\n",
    "* des **fichiers** : ces fichiers peuvent prendre n'importe quelle forme (png, jpeg, gif, txt, ...) et ne sont pas modifiables au cours du 'run. Ici nous avons fait une copie du fichier ```iris.csv```.\n",
    "\n",
    "Toutes ces variables sont regroupées dans un même 'run', ici nommé 'Modele_Aleatoire'. Un 'run' correspond à une ligne du tableau. Les 'runs' peuvent être regroupés en 'experiences', ici nommée ```Default``` dans la colonne de gauche. Nous verons comment changer le nom de l'expérience par la suite.\n",
    "\n",
    "Reprenons les lignes de code qui nous ont permis de faire tout ça :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Création du 'run' ML FLow, nommé ici 'Modele_Aleatoire'\n",
    "#    Tous les paramètres, métriques ou fichiers que nous enregistrerons ensuite\n",
    "#    seront enregistré dans ce 'run', qui correspond à une ligne du tableau\n",
    "with mlflow.start_run(run_name='Modele_Aleatoire'):\n",
    "\n",
    "    # 2. Enregistrement d'un paramètre\n",
    "    mlflow.log_param('MODEL_NAME', 'DummyClassifier')\n",
    "\n",
    "    # 3. Enregistrement d'une métrique\n",
    "    mlflow.log_metric('Accuracy', accuracy_score(Y, Y_pred))\n",
    "\n",
    "    # 4. Enregistrement d'un fichier\n",
    "    mlflow.log_artifact('iris.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice d'application\n",
    "\n",
    "En traçant l'histogramme des échantillons selon la valeur de ```petal-width```, on voit qu'on peut assez facilement discriminer les échantillons selon cette variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.groupby('class')['petal-width'].plot.hist()\n",
    "plt.xlabel('petal-width')\n",
    "plt.title('Histogramme des échantillons selon la valeur de petal-width')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Nous allons donc essayer de coder notre propre modèle de classification selon cette spécificité et enregistrer ses performances avec ML FLow.\n",
    "\n",
    "Pour cela, commencez par coder une fonction qui :\n",
    "* prend en entrée une liste d'échantillons\n",
    "* retourne la liste des classes des échantillons\n",
    "* attribue la classe selon la valeur de ```petal-width``` (dernière colonne de l'échantillon). On pourra par exemple déterminer la classe en comparant ```petal-width``` à des seuils bien choisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution1\n",
    "# Si vous êtes bloqués, décommentez la ligne précédente et exécutez là pour afficher une solution\n",
    "\n",
    "def simple_classification_model(list_samples):\n",
    "    list_classes = []\n",
    "\n",
    "    # AJOUTEZ VOTRE CODE ICI\n",
    "\n",
    "    return list_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifions ici que notre modele fonctionne sur quelques échantillons :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = simple_classification_model(X)\n",
    "for i in range(5):\n",
    "    print(X[i], ', vraie classe : ', Y[i], ', prédiction : ', Y_pred[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant à vous d'utiliser MLFLow pour enregistrer l'accuracy de ce nouveau modèle !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution2\n",
    "# Si vous êtes bloqués, décommentez la ligne précédente et exécutez là pour afficher une solution\n",
    "\n",
    "# AJOUTER VOTRE CODE ICI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ML Flow : Comparaison de plusieurs modèles\n",
    "\n",
    "Nous allons maintenant entraîner différents modèles sur le jeu de données et voir comment nous pouvons les comparer facilement avec ML FLow. Pour cela, nous allons créer plusieurs modèles et estimer leurs performances sur des données qu'ils n'ont pas vu pendant l'entraînement. Commençons par séparer notre dataset en deux parties : une pour l'entraînement et une pour le test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construisons la liste des modèles à tester :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "models = []\n",
    "models.append(('LogisticRegression', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('LinearDiscriminantAnalysis', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNeighborsClassifier', KNeighborsClassifier()))\n",
    "models.append(('DecisionTreeClassifier', DecisionTreeClassifier()))\n",
    "models.append(('GaussianNB', GaussianNB()))\n",
    "models.append(('SVM', SVC(gamma='auto')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajoutons cette fonction qui va nous permettre de tracer de jolies matrices de confusion par la suite :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, target_names, title, \n",
    "                          normalize=True, save_path='matrix.png'):\n",
    "    import itertools\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    if normalize: cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    cmap = plt.get_cmap('Blues')\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap, vmin=0, vmax=1)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(target_names))\n",
    "    plt.xticks(tick_marks, target_names, rotation=45)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'\\\n",
    "               .format(accuracy, misclass))\n",
    "    plt.gcf().canvas.draw()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant entraîner nos modèles et enregistrer leurs paramètres et métriques avec ML Flow. \n",
    "\n",
    "Nous allons voir deux nouvelles choses : \n",
    "* Comment créer une nouvelle expérience\n",
    "* Comment enregistrer plusieurs paramètres ou métriques d'un seul coup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Création d'une nouvelle expérience\n",
    "#    Tous les nouveaux runs seront enregistrés dans cette expérience\n",
    "mlflow.set_experiment('Comparaison')\n",
    "\n",
    "for name, model in models:\n",
    "    print(name)\n",
    "\n",
    "    # 2. Création et début d'un nouveau run\n",
    "    with mlflow.start_run(run_name=name):\n",
    "\n",
    "        # 3. Enregistrement de plusieurs paramètres sous forme d'un dictionnaire\n",
    "        params = {}\n",
    "        params['MODEL_NAME'] = name\n",
    "        params['TRAIN_SIZE'] = len(X_train)\n",
    "        params['TEST_SIZE'] = len(X_val)\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # On note le moment du début de l'expérience pour mesurer la durée de l'entraînement\n",
    "        start = time.time()\n",
    "\n",
    "        # Entraînement du modèle\n",
    "        model.fit(X_train, Y_train)\n",
    "\n",
    "        training_time = time.time() - start\n",
    "\n",
    "        predictions = model.predict(X_val)\n",
    "\n",
    "        # 4. Enregistrement de plusieurs métriques sous forme d'un dictionnaire\n",
    "        metrics = {}\n",
    "        metrics['Accuracy'] = accuracy_score(Y_val, predictions)\n",
    "        metrics['Precision'] = precision_score(Y_val, predictions, average='macro')\n",
    "        metrics['Recall'] = recall_score(Y_val, predictions, average='macro')\n",
    "        metrics['Training Time'] = training_time\n",
    "        mlflow.log_metrics(metrics)\n",
    "\n",
    "        # 5. Enregistrement de la matrice de confusion\n",
    "        cm = confusion_matrix(Y_val, predictions)\n",
    "        plot_confusion_matrix(cm, ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'],\n",
    "                              'Confusion matrix '+name)\n",
    "        mlflow.log_artifact('matrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retournez maintenant sur votre navigateur pour voir le résultat dans le dashboard ML Flow.\n",
    "\n",
    "Vous devriez voir une nouvelle expérience 'Comparaison' dans la liste des expériences à gauche. En cliquant dessus vous pourrez voir apparaître les 6 runs que nous venons de lancer. Selectionnez les tous et cliquez sur ```Compare```. Vous pouvez maintenant facilement comparer toutes les caractéristiques de nos modèles. En cliquant sur le nom d'une des métriques vous pourrez afficher un diagramme comparant les valeurs pour tous les modèles.\n",
    "\n",
    "Revenez au tableau des runs et ouvrer l'un des runs. Dans la partie ```Artifacts``` vous pourrez voir la superbe matrice de confusion que nous avons tracé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice d'application\n",
    "\n",
    "Nous pouvons maintenant comparer le modèle que nous avions codé précedemment dans la fonction ```simple_classification_model``` avec les autres modèles, en enregistrant tout cela dans MLFlow. A vous de jouer !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution3\n",
    "# Si vous êtes bloqués, décommentez la ligne précédente et exécutez là pour afficher une solution\n",
    "\n",
    "# AJOUTEZ VOTRE CODE ICI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ML Flow : Enregistrer l'évolution d'une métrique\n",
    "\n",
    "Dans cette dernière partie, nous allons voir comment enregistrer l'évolution d'une métrique au cours du temps. Pour cela, nous allons utiliser comme modèle un réseau de neurones basique : le perceptron multi-couches.\n",
    "\n",
    "Afin de calculer nos métriques au cours de l'entrainement, nous decoupons celui-ci en plusieurs epochs. A chaque epoch, le reseau de neurone s'entraîne une fois sur l'intégralité du dataset. Tout ceci est fait automatiquement dans la fonction ```fit``` par défaut de scikit learn, mais nous allons faire les choses manuellement ici, pour visualiser l'évolution des métriques au cours de l'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import time\n",
    "\n",
    "# 1. Création et début d'un nouveau run\n",
    "with mlflow.start_run(run_name='Multilayer Perceptron'):\n",
    "\n",
    "    model = MLPClassifier(max_iter=10)\n",
    "    mlflow.log_param('MODEL_NAME', 'MLPClassifier')\n",
    "\n",
    "    N_TRAIN_SAMPLES = X_train.shape[0]\n",
    "    N_EPOCHS = 50\n",
    "    N_BATCH = 8\n",
    "    N_CLASSES = np.unique(Y_train)\n",
    "    scores_train = []\n",
    "    scores_test = []\n",
    "\n",
    "    # EPOCH\n",
    "    epoch = 0\n",
    "    while epoch < N_EPOCHS:\n",
    "        if epoch % 5 == 0 : print('Epoch: ', epoch)\n",
    "        # SHUFFLING\n",
    "        random_perm = np.random.permutation(X_train.shape[0])\n",
    "        mini_batch_index = 0\n",
    "        while True:\n",
    "            # TRAIN ON MINI-BATCH\n",
    "            indices = random_perm[mini_batch_index:mini_batch_index + N_BATCH]\n",
    "            model.partial_fit(X_train[indices], Y_train[indices], classes=N_CLASSES)\n",
    "            mini_batch_index += N_BATCH\n",
    "            if mini_batch_index >= N_TRAIN_SAMPLES:\n",
    "                break\n",
    "\n",
    "        metrics = {}\n",
    "        predictions = model.predict(X_val)\n",
    "        metrics['Accuracy'] = accuracy_score(Y_val, predictions)\n",
    "        metrics['Precision'] = precision_score(Y_val, predictions, average='macro')\n",
    "        metrics['Recall'] = recall_score(Y_val, predictions, average='macro')\n",
    "        metrics['Loss'] = model.loss_\n",
    "        # 2. Enregistrement de plusieurs métriques pour une epoch donnée\n",
    "        mlflow.log_metrics(metrics, step=epoch)\n",
    "        time.sleep(3)\n",
    "\n",
    "        epoch += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revenez sur le tableau des runs dans le dashboard et ouvrez le run que nous venons de créer. En cliquant sur l'une des métriques, vous pourrez voir son évolution au cours de l'apprentissage du réseau de neurones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Un exercice d'application météo\n",
    "\n",
    "Pour finir, je vous propose un exercice d'application sur le thème de la météo, qui regroupera tout ce que nous avons appris ici.\n",
    "\n",
    "Pour cela nous allons étudier la température sur l'île d'Ouessant : le fichier ```ouessant_temperature.csv``` contient l'historique des températures à Ouessant, mesurées toutes les 6 minutes durant l'année 2018.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_dataset = pd.read_csv('ouessant_temperature.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_dataset.t.plot(figsize=(15,7))\n",
    "plt.title(\"Température sur l'île d'Ouessant au cours de l'année 2018\")\n",
    "plt.ylabel('Température (K)')\n",
    "plt.xlabel('Mois')\n",
    "plt.xlim(0,87453)\n",
    "plt.xticks(np.arange(0,87453,7286), ['J','F','M','A','M','J','J','A','S','O','N','D'])\n",
    "plt.grid(axis='both')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre objectif est de comparer des modèles de prévision de température. Ces modèles prendront en entrée l'historique des températures sur 2h et devront prévoir la température pendant l'heure suivante.\n",
    "\n",
    "Commençons par créer notre dataset de séquences de température sur 3h."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = meteo_dataset.t.values\n",
    "len_sequence = 30   # 10 samples per hour during 3 hours\n",
    "dataset = []\n",
    "i = 0\n",
    "while i < len(data)-len_sequence:\n",
    "    dataset.append(data[i:i+len_sequence])\n",
    "    i += len_sequence\n",
    "dataset = np.stack(dataset, axis=0)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Séparons les données en X et Y, puis créons un jeu d'entraînement et un jeu de test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,:20]\n",
    "Y = dataset[:,20:]\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, à vous de jouer ! \n",
    "* Créez au moins **3 modèles de prévisions** de températures comme nous l'avons fait dans le premier exercice. On pourra commencer par des modèles simples tels que la persistance.\n",
    "* Ajoutez au moins **3 métriques** pour évaluer les performances de vos modèles.\n",
    "* Pour chaque métrique, évaluez là sur l'ensemble de votre prévision, mais aussi sur chacune des échéances (t1, t2, t3,...) afin de tracer dans MLFlow la courbe d'évolution de cette métrique.\n",
    "* Enregistrez tout cela dans MLFlow, dans une nouvelle expérience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AJOUTEZ VOTRE CODE ICI"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
